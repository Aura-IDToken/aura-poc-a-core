# compliance/renderer.py

"""
Compliance output renderer for Aura Protocol.

Transforms AuraEventCertificate into human-readable formats
while maintaining compliance with AI Act transparency requirements.
"""

from typing import Dict, Any
from .certificate import AuraEventCertificate


def render_certificate(cert: AuraEventCertificate, format: str = "json") -> str:
    """
    Render an AuraEventCertificate in the specified format.
    
    Args:
        cert: The certificate to render
        format: Output format ('json', 'text', 'compliance')
    
    Returns:
        Formatted certificate string
    
    Note: Uses Agent Reliability Index (ARI) terminology to comply
    with AI Act and avoid Social Scoring classification.
    """
    if format == "json":
        import json
        return json.dumps(cert.to_dict(), indent=2, sort_keys=True)
    
    elif format == "text":
        return _render_text(cert)
    
    elif format == "compliance":
        return _render_compliance_report(cert)
    
    else:
        raise ValueError(f"Unsupported format: {format}")


def _render_text(cert: AuraEventCertificate) -> str:
    """Render certificate as human-readable text."""
    return f"""
AURA PROTOCOL CERTIFICATE
========================

Agent ID: {cert.agent_id} (MACHINE_ACCOUNT)
Timestamp: {cert.timestamp}

AGENT RELIABILITY INDEX (ARI)
-----------------------------
Score: {cert.ari_score:.4f}
Drift: {cert.drift:.4f}
Status: {cert.status}

Formula: ARI = 0.3 * StructuralIntegrity + 0.7 * SemanticAlignment - Penalties
Semantic Space: ℝ¹⁵³⁶ (Cosine Similarity)

AUDIT TRAIL
-----------
Leaf Hash: {cert.leaf_hash}
Merkle Root: {cert.merkle_root}
Certificate Fingerprint: {cert.fingerprint()}

COMPLIANCE
----------
Scope: MACHINE_ACCOUNT entities only
AI Act Art. 5: No human profiling or biometric data
Krasinski Principle: Transparency ∝ 1/Secrecy
Determinism: Guaranteed (same input → same ARI)
"""


def _render_compliance_report(cert: AuraEventCertificate) -> str:
    """Render certificate as AI Act compliance report."""
    return f"""
AI ACT TRANSPARENCY REPORT
=========================
Generated by: Aura Protocol (Proof of Consistent Agency)
Standard: EU AI Act Article 13 (Transparency & Traceability)

SYSTEM CLASSIFICATION
--------------------
System Type: Agent Reliability Monitoring
Scope: MACHINE_ACCOUNT entities ONLY
Human Profiling: PROHIBITED (Art. 5 compliance)
Biometric Data: PROHIBITED (Art. 5 compliance)

EVALUATION DETAILS
-----------------
Agent ID: {cert.agent_id}
Evaluation Time: {cert.timestamp}
Agent Reliability Index: {cert.ari_score:.4f}

MATHEMATICAL FOUNDATION
----------------------
Formula: ARI = 0.3 × SI + 0.7 × SA - P
Where:
  SI = Structural Integrity (binary: 0.0 or 1.0)
  SA = Semantic Alignment (cosine similarity in ℝ¹⁵³⁶)
  P = Policy Penalties (sum of violations)

Krasinski Principle: T ∝ 1/S
  Transparency (T) inversely proportional to Secrecy/Entropy (S)
  Trust modeled as behavioral consistency, not moral virtue

CRYPTOGRAPHIC AUDIT
------------------
Merkle Root: {cert.merkle_root}
Leaf Hash: {cert.leaf_hash}
Certificate Hash: {cert.fingerprint()}

Non-repudiation: Supported via Merkle proofs
Tamper Evidence: Cryptographic hash chain
Determinism: Same input yields identical ARI

REGULATORY COMPLIANCE
--------------------
✓ No Social Scoring (uses "ARI" not "Trust Score")
✓ Agent-only scope (no human subjects)
✓ Deterministic evaluation (reproducible)
✓ Cryptographic audit trail (non-repudiable)
✓ Transparency by design (Krasinski Principle)

Status: {cert.status}
"""
